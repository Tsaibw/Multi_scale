{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4af431-5cea-4016-838d-4021fcc92bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#一定要先，不然torch會偵測不到\n",
    "!export CUDA_VISIBLE_DEVICES=4\n",
    "%set_env CUDA_VISIBLE_DEVICES=4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98b167fa-d364-4172-9613-5ac05c2c4deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from transformers import BertModel, BertConfig\n",
    "from torch.optim import Adam\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.nn.utils import clip_grad_value_\n",
    "from tqdm import tqdm\n",
    "from data.dataloader import CustomDataset\n",
    "from model.multi_bert import multiBert\n",
    "from data.scale import get_scaled_down_scores, separate_and_rescale_attributes_for_scoring\n",
    "from utils.evaluate import evaluation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44e81446-8d44-4ad5-91f4-3a0d29918e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "torch.manual_seed(11)\n",
    "\n",
    "class NerConfig:\n",
    "    def __init__(self):\n",
    "        self.lr = 1e-5\n",
    "        self.epoch = 15\n",
    "        self.batch_size = 12\n",
    "        self.device = \"cuda\"\n",
    "        self.chunk_sizes = [90]\n",
    "        self.data_file = \"/home/tsaibw/Multi_scale/ckps/chunk_90\"\n",
    "args = NerConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4b6d41f-1c24-4517-ae1b-bdbb2858ee50",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda/envs/protact/lib/python3.8/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Epoch 1/15: 100% 75/75 [00:57<00:00,  1.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson :  -0.642\n",
      "QWK :  -0.137\n",
      "Epoch 0, Train Loss: 0.5873666714131832\n",
      "Test Loss: 0.09719806015491486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/15: 100% 75/75 [00:57<00:00,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson :  0.508\n",
      "QWK :  0.113\n",
      "Epoch 1, Train Loss: 0.12487845321496328\n",
      "Test Loss: 0.04140287674963474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/15: 100% 75/75 [00:58<00:00,  1.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson :  0.484\n",
      "QWK :  0.143\n",
      "Epoch 2, Train Loss: 0.09129460168381533\n",
      "Test Loss: 0.02152123786509037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/15: 100% 75/75 [00:57<00:00,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson :  0.588\n",
      "QWK :  0.356\n",
      "Epoch 3, Train Loss: 0.05846137084066868\n",
      "Test Loss: 0.0168944222231706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/15: 100% 75/75 [00:57<00:00,  1.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson :  0.589\n",
      "QWK :  0.358\n",
      "Epoch 4, Train Loss: 0.0481412306924661\n",
      "Test Loss: 0.01852664121737083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/15: 100% 75/75 [00:58<00:00,  1.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson :  0.207\n",
      "QWK :  0.016\n",
      "Epoch 5, Train Loss: 0.045498618533213936\n",
      "Test Loss: 0.02126310607418418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/15: 100% 75/75 [00:57<00:00,  1.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson :  0.207\n",
      "QWK :  0.016\n",
      "Epoch 6, Train Loss: 0.04639702626814445\n",
      "Test Loss: 0.023182655808826287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/15: 100% 75/75 [00:59<00:00,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson :  0.207\n",
      "QWK :  0.016\n",
      "Epoch 7, Train Loss: 0.045787829694648584\n",
      "Test Loss: 0.022919519680241744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/15: 100% 75/75 [00:58<00:00,  1.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson :  0.207\n",
      "QWK :  0.016\n",
      "Epoch 8, Train Loss: 0.04424444705247879\n",
      "Test Loss: 0.02536022998392582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/15: 100% 75/75 [01:00<00:00,  1.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson :  0.318\n",
      "QWK :  0.08\n",
      "Epoch 9, Train Loss: 0.0407459406927228\n",
      "Test Loss: 0.030371446597079434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/15: 100% 75/75 [00:59<00:00,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson :  0.342\n",
      "QWK :  0.14\n",
      "Epoch 10, Train Loss: 0.03502129915480812\n",
      "Test Loss: 0.026542170842488607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/15: 100% 75/75 [01:00<00:00,  1.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson :  0.377\n",
      "QWK :  0.18\n",
      "Epoch 11, Train Loss: 0.030374603973080713\n",
      "Test Loss: 0.031469534647961456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/15: 100% 75/75 [01:00<00:00,  1.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson :  0.455\n",
      "QWK :  0.24\n",
      "Epoch 12, Train Loss: 0.027945026823629936\n",
      "Test Loss: 0.03252855117122332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/15: 100% 75/75 [01:01<00:00,  1.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson :  0.404\n",
      "QWK :  0.189\n",
      "Epoch 13, Train Loss: 0.024981539969642957\n",
      "Test Loss: 0.03944007282455762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/15: 100% 75/75 [01:00<00:00,  1.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson :  0.489\n",
      "QWK :  0.274\n",
      "Epoch 14, Train Loss: 0.022414098136747877\n",
      "Test Loss: 0.03403735980391502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/15: 100% 75/75 [01:00<00:00,  1.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson :  -0.608\n",
      "QWK :  -0.586\n",
      "Epoch 0, Train Loss: 0.8197053261597951\n",
      "Test Loss: 0.061110729227463405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/15:  93% 70/75 [00:57<00:04,  1.23it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 46\u001b[0m\n\u001b[1;32m     43\u001b[0m     loss, inverse_predictions, inverse_labels \u001b[38;5;241m=\u001b[39m multi_bert_model\u001b[38;5;241m.\u001b[39mcompute_loss(predictions, label, id_, args\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m     44\u001b[0m     total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m---> 46\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     49\u001b[0m eval_loss, qwk_score, pearson_score \u001b[38;5;241m=\u001b[39m multi_bert_model\u001b[38;5;241m.\u001b[39mevaluate(eval_loader, device \u001b[38;5;241m=\u001b[39m args\u001b[38;5;241m.\u001b[39mdevice)\n",
      "File \u001b[0;32m/opt/miniconda/envs/protact/lib/python3.8/site-packages/torch/_tensor.py:488\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    479\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    480\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    481\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    486\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    487\u001b[0m     )\n\u001b[0;32m--> 488\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda/envs/protact/lib/python3.8/site-packages/torch/autograd/__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    192\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    194\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 197\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train normalize\n",
    "\n",
    "def save_checkpoint(state, filename=\"checkpoint.pth.tar\"):\n",
    "    torch.save(state, filename)\n",
    "\n",
    "\n",
    "def print_gradients(model):\n",
    "    for name, parameter in model.named_parameters():\n",
    "        if parameter.grad is not None:\n",
    "            print(f\"{name} - Gradient Norm: {parameter.grad.norm().item()}\")\n",
    "        else:\n",
    "            print(f\"{name} - No gradient\")\n",
    "\n",
    "\n",
    "for i in range(1,9):\n",
    "    multi_bert_model = multiBert(args.chunk_sizes)  \n",
    "    multi_bert_model.to(args.device)  \n",
    "    optimizer = Adam(multi_bert_model.parameters(), lr = args.lr) \n",
    "    \n",
    "    train_dataset = CustomDataset(f\"/home/tsaibw/Multi_scale/dataset/train/encode_prompt_{i}.pkl\")\n",
    "    eval_dataset = CustomDataset(f\"/home/tsaibw/Multi_scale/dataset/test/encode_prompt_{i}.pkl\")\n",
    "    train_loader = DataLoader(train_dataset, batch_size=args.batch_size, shuffle=False, num_workers=4)\n",
    "    eval_loader = DataLoader(eval_dataset, batch_size=args.batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "    train_loss_list , eval_loss_list = [] ,[] \n",
    "    os.makedirs(f\"{args.data_file}/prompt{i}\", exist_ok=True)\n",
    "    \n",
    "    for epoch in range(args.epoch):\n",
    "        multi_bert_model.train()\n",
    "        total_loss = 0\n",
    "\n",
    "        for document_single, chunked_documents, label, id_, lengths in tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{args.epoch}\"):\n",
    "            document_single = document_single.to(args.device)\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            predictions = multi_bert_model(\n",
    "                    document_single=document_single,\n",
    "                    chunked_documents=chunked_documents,\n",
    "                    device=args.device,\n",
    "                    lengths=lengths\n",
    "            )\n",
    "            \n",
    "            loss, inverse_predictions, inverse_labels = multi_bert_model.compute_loss(predictions, label, id_, args.device)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        eval_loss, qwk_score, pearson_score = multi_bert_model.evaluate(eval_loader, device = args.device)\n",
    "        \n",
    "        print(f\"Epoch {epoch}, Train Loss: {total_loss / len(train_loader)}\")\n",
    "        print(f\"Test Loss: {eval_loss}\")\n",
    "        train_loss_list.append(total_loss / len(train_loader))\n",
    "        eval_loss_list.append(eval_loss)\n",
    "\n",
    "        qwk_path = f\"{args.data_file}/prompt{i}/result.txt\"\n",
    "        with open(qwk_path, \"a\") as f:\n",
    "            f.write(f\"Epoch {epoch + 1}/{args.epoch}, QWK: {qwk_score}, Pearson: {pearson_score}, train_loss: {train_loss_list[-1]}, eval_loss: {eval_loss_list[-1]}\\n\")\n",
    "  \n",
    "        checkpoint_path = f\"{args.data_file}/prompt{i}/epoch_{epoch+1}_checkpoint.pth.tar\"\n",
    "        save_checkpoint({\n",
    "          'epoch': epoch + 1,\n",
    "          'state_dict': multi_bert_model.state_dict(),\n",
    "          'optimizer': optimizer.state_dict(),\n",
    "          'train_loss': total_loss / len(train_loader),\n",
    "          'eval_loss': eval_loss\n",
    "        }, filename = checkpoint_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b8b32a-d5b1-401b-8977-dd7912cee561",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env ProTact",
   "language": "python",
   "name": "protact"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
