{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62fc7361-a55f-429f-a144-b544f5503727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=3\n"
     ]
    }
   ],
   "source": [
    "!export CUDA_VISIBLE_DEVICES=3\n",
    "%set_env CUDA_VISIBLE_DEVICES=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c42bae2e-b99e-4ba8-8aeb-84866b80a89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pickle\n",
    "from transformers import TrainingArguments\n",
    "from torch.utils.data import RandomSampler, DataLoader\n",
    "from data.dataloader import CustomDataset\n",
    "from model.model_architechure_bert import multiBert as Model\n",
    "from trainers import BertTrainer\n",
    "from utils.callbacks import EvaluateRecord\n",
    "from utils.general_utils import seed_all\n",
    "from utils.multitask_evaluator_all_attributes import Evaluator\n",
    "from safetensors.torch import load_file\n",
    "from torch.utils.data.dataloader import default_collate\n",
    "class NerConfig:\n",
    "    def __init__(self):\n",
    "        self.device = \"cuda\"\n",
    "        self.num_trait = 9\n",
    "        self.alpha = 0.7\n",
    "        self.delta = 0.7\n",
    "        self.filter_num = 100\n",
    "        self.chunk_sizes = [90, 30, 130, 10]\n",
    "        self.data_file = \"/home/tsaibw/Multi_scale/ckps/feacture\"\n",
    "        self.hidden_dim = 100 # chunk & linear output_dim\n",
    "        self.mhd_head = 2\n",
    "args = NerConfig()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "019c28aa-e720-4295-9fe9-58729a15f804",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda/envs/protact/lib/python3.8/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------\n",
      "CURRENT EPOCH: None\n",
      "[DEV] AVG QWK: 0.807\n",
      "[DEV] score QWK: 0.959\n",
      "[DEV] content QWK: 0.882\n",
      "[DEV] prompt_adherence QWK: 0.679\n",
      "[DEV] language QWK: 0.691\n",
      "[DEV] narrativity QWK: 0.699\n",
      "[DEV] organization QWK: 0.847\n",
      "[DEV] word_choice QWK: 0.85\n",
      "[DEV] sentence_fluency QWK: 0.849\n",
      "[DEV] conventions QWK: 0.809\n",
      "------------------------\n",
      "[TEST] AVG QWK: 0.598\n",
      "[TEST] score QWK: 0.497\n",
      "[TEST] content QWK: 0.578\n",
      "[TEST] organization QWK: 0.643\n",
      "[TEST] word_choice QWK: 0.636\n",
      "[TEST] sentence_fluency QWK: 0.626\n",
      "[TEST] conventions QWK: 0.606\n",
      "------------------------\n",
      "[BEST TEST] AVG QWK: 0.598, epoch: None\n",
      "[BEST TEST] score QWK: 0.497\n",
      "[BEST TEST] content QWK: 0.578\n",
      "[BEST TEST] organization QWK: 0.643\n",
      "[BEST TEST] word_choice QWK: 0.636\n",
      "[BEST TEST] sentence_fluency QWK: 0.626\n",
      "[BEST TEST] conventions QWK: 0.606\n",
      "--------------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def train(\n",
    "    test_prompt_id: int = 1,\n",
    "    experiment_tag: str = \"test\",\n",
    "    seed: int = 11,\n",
    "    num_train_epochs: int = 15,\n",
    "    batch_size: int = 12,\n",
    "    gradient_accumulation: int = 1,\n",
    "    learning_rate: float = 1e-5,\n",
    "    weight_decay: float = 0.01,\n",
    "    chunk_sizes: int = [90, 30, 130, 10]\n",
    "):\n",
    "    seed_all(seed)\n",
    "\n",
    "    train_dataset = CustomDataset(f\"/home/tsaibw/Multi_scale/dataset/var_norm/new_train/encode_prompt_{test_prompt_id}.pkl\")\n",
    "    eval_dataset = CustomDataset(f\"/home/tsaibw/Multi_scale/dataset/var_norm/new_dev/encode_prompt_{test_prompt_id}.pkl\")\n",
    "    test_dataset = CustomDataset(f\"/home/tsaibw/Multi_scale/dataset/var_norm/new_test/encode_prompt_{test_prompt_id}.pkl\")\n",
    "    model = Model(\n",
    "        args=args\n",
    "    )\n",
    "    evaluator = Evaluator(eval_dataset, test_dataset, seed)\n",
    "\n",
    "    output_dir = f\"ckpts/trait_var/prompt_{test_prompt_id}\"\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        learning_rate = learning_rate,\n",
    "        num_train_epochs = num_train_epochs,\n",
    "        per_device_train_batch_size = batch_size,\n",
    "        per_device_eval_batch_size = batch_size,\n",
    "        gradient_accumulation_steps = gradient_accumulation,\n",
    "        logging_dir = f\"logs/{experiment_tag}/trait_var/prompt_{test_prompt_id}\",\n",
    "        evaluation_strategy = \"epoch\",\n",
    "        label_names = [\"scaled_score\"],\n",
    "        save_strategy = \"epoch\",\n",
    "        save_total_limit = 5,\n",
    "        do_eval = True,\n",
    "        load_best_model_at_end = True, \n",
    "        fp16 = False,\n",
    "        remove_unused_columns = True,\n",
    "        metric_for_best_model = \"eval_test_avg\",\n",
    "        greater_is_better = True,\n",
    "        seed = seed,\n",
    "        data_seed = seed,\n",
    "        ddp_find_unused_parameters = False\n",
    "    )\n",
    "            \n",
    "    trainer = BertTrainer(\n",
    "        model = model,\n",
    "        args = training_args,\n",
    "        train_dataset = train_dataset,\n",
    "        eval_dataset = eval_dataset,\n",
    "        test_dataset = test_dataset,\n",
    "        evaluator = evaluator,\n",
    "        callbacks = [EvaluateRecord(output_dir)],\n",
    "        data_collator = default_collate,\n",
    "    )\n",
    "\n",
    "    print('Trainer is using device:', trainer.args.device)\n",
    "    print(test_prompt_id)\n",
    "    trainer.train()\n",
    "    # trainer.train(resume_from_checkpoint = )\n",
    "\n",
    "def inference(test_prompt_id, model_path, data_path):\n",
    "    \n",
    "    train_dataset = CustomDataset(f\"{data_path}/new_train/encode_prompt_{test_prompt_id}.pkl\")\n",
    "    eval_dataset = CustomDataset(f\"{data_path}/new_dev/encode_prompt_{test_prompt_id}.pkl\")\n",
    "    test_dataset = CustomDataset(f\"{data_path}/new_test/encode_prompt_{test_prompt_id}.pkl\") \n",
    "    args = NerConfig()\n",
    "    model = Model(\n",
    "        args=args\n",
    "    )\n",
    "    weights = load_file(model_path)\n",
    "    model.load_state_dict(weights)\n",
    "    output_dir = f\"ckpts/trait_var/prompt_{test_prompt_id}\"\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir = output_dir,\n",
    "        per_device_eval_batch_size = 512,\n",
    "        label_names=[\"scaled_score\"],\n",
    "        do_train = False, \n",
    "        do_eval = True,\n",
    "    )\n",
    "    evaluator = Evaluator(eval_dataset, test_dataset, seed=11)\n",
    "    \n",
    "    trainer = BertTrainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        eval_dataset = eval_dataset,\n",
    "        test_dataset = test_dataset,\n",
    "        evaluator = evaluator,\n",
    "        data_collator = default_collate,\n",
    "    )\n",
    "\n",
    "    prediction_output = trainer.predict(eval_dataset)\n",
    "if __name__ == \"__main__\":\n",
    "    test_prompt_id = 1\n",
    "    model_path = f'/home/tsaibw/Multi_scale/ckpts/trait_var/prompt_{test_prompt_id}/checkpoint-793/model.safetensors'\n",
    "    data_path = f\"/home/tsaibw/Multi_scale/dataset/var_norm\"\n",
    "    inference(test_prompt_id, model_path, data_path)\n",
    "    # for i in range(1,9):\n",
    "    #     train(test_prompt_id = i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd54c6b-7fda-4e00-adc9-7b10d4ab9113",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018d8b9e-de68-494c-9b86-ab950ef45b9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env ProTact",
   "language": "python",
   "name": "protact"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
