{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62fc7361-a55f-429f-a144-b544f5503727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=3\n"
     ]
    }
   ],
   "source": [
    "!export CUDA_VISIBLE_DEVICES=3\n",
    "%set_env CUDA_VISIBLE_DEVICES=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c42bae2e-b99e-4ba8-8aeb-84866b80a89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fire\n",
    "import os\n",
    "import torch\n",
    "import pickle\n",
    "from transformers import TrainingArguments\n",
    "from torch.utils.data import RandomSampler, DataLoader\n",
    "from data.dataloader import CustomDataset\n",
    "from model.multi_bert import multiBert as Model\n",
    "from trainers import BertTrainer\n",
    "from utils.callbacks import EvaluateRecord\n",
    "from utils.general_utils import seed_all\n",
    "from utils.multitask_evaluator_all_attributes import Evaluator\n",
    "from safetensors.torch import load_file\n",
    "from torch.utils.data.dataloader import default_collate\n",
    "class NerConfig:\n",
    "    def __init__(self):\n",
    "        self.lr = 1e-5\n",
    "        self.epoch = 15\n",
    "        self.batch_size = 10\n",
    "        self.device = \"cuda\"\n",
    "        self.num_trait = 9\n",
    "        self.alpha = 0.7\n",
    "        self.delta = 0.7\n",
    "        self.filter_num = 100\n",
    "        self.chunk_sizes = [90, 30, 130, 10]\n",
    "        self.data_file = \"/home/tsaibw/Multi_scale/ckps/feacture\"\n",
    "        self.hidden_dim = 100 # chunk & linear output_dim\n",
    "        self.mhd_head = 2\n",
    "args = NerConfig()\n",
    "from torch.utils.data import Subset\n",
    "import numpy as np\n",
    "\n",
    "# ‰ΩøÁî®Âõ∫ÂÆöÈö®Ê©üÁ®ÆÂ≠ê‰ª•‰øùË≠âÂ≠êÈõÜ‰∏ÄËá¥ÊÄß\n",
    "def get_subset(dataset, fraction=0.1, seed=42):\n",
    "    np.random.seed(seed)\n",
    "    dataset_size = len(dataset)\n",
    "    indices = np.random.permutation(dataset_size)[:int(fraction * dataset_size)]\n",
    "    return Subset(dataset, indices)\n",
    "\n",
    "# ‰øÆÊîπ train_dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019c28aa-e720-4295-9fe9-58729a15f804",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda/envs/protact/lib/python3.8/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/opt/miniconda/envs/protact/lib/python3.8/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainer is using device: cuda:0\n",
      "6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2110' max='8316' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2110/8316 1:43:21 < 5:04:16, 0.34 it/s, Epoch 3.55/14]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Dev Avg</th>\n",
       "      <th>Test Avg</th>\n",
       "      <th>Dev Score</th>\n",
       "      <th>Dev Content</th>\n",
       "      <th>Dev Organization</th>\n",
       "      <th>Dev Word Choice</th>\n",
       "      <th>Dev Sentence Fluency</th>\n",
       "      <th>Dev Conventions</th>\n",
       "      <th>Dev Prompt Adherence</th>\n",
       "      <th>Dev Language</th>\n",
       "      <th>Dev Narrativity</th>\n",
       "      <th>Test Score</th>\n",
       "      <th>Test Content</th>\n",
       "      <th>Test Prompt Adherence</th>\n",
       "      <th>Test Language</th>\n",
       "      <th>Test Narrativity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.069800</td>\n",
       "      <td>0.043584</td>\n",
       "      <td>0.662015</td>\n",
       "      <td>0.285415</td>\n",
       "      <td>0.942000</td>\n",
       "      <td>0.819000</td>\n",
       "      <td>0.673000</td>\n",
       "      <td>0.719000</td>\n",
       "      <td>0.709000</td>\n",
       "      <td>0.601000</td>\n",
       "      <td>0.491000</td>\n",
       "      <td>0.499000</td>\n",
       "      <td>0.504000</td>\n",
       "      <td>0.269000</td>\n",
       "      <td>0.259000</td>\n",
       "      <td>0.260000</td>\n",
       "      <td>0.331000</td>\n",
       "      <td>0.308000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.044700</td>\n",
       "      <td>0.036089</td>\n",
       "      <td>0.673677</td>\n",
       "      <td>0.266574</td>\n",
       "      <td>0.943000</td>\n",
       "      <td>0.813000</td>\n",
       "      <td>0.680000</td>\n",
       "      <td>0.745000</td>\n",
       "      <td>0.736000</td>\n",
       "      <td>0.642000</td>\n",
       "      <td>0.488000</td>\n",
       "      <td>0.504000</td>\n",
       "      <td>0.512000</td>\n",
       "      <td>0.225000</td>\n",
       "      <td>0.254000</td>\n",
       "      <td>0.252000</td>\n",
       "      <td>0.312000</td>\n",
       "      <td>0.289000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.038800</td>\n",
       "      <td>0.042767</td>\n",
       "      <td>0.733965</td>\n",
       "      <td>0.480573</td>\n",
       "      <td>0.954000</td>\n",
       "      <td>0.811000</td>\n",
       "      <td>0.738000</td>\n",
       "      <td>0.802000</td>\n",
       "      <td>0.752000</td>\n",
       "      <td>0.673000</td>\n",
       "      <td>0.622000</td>\n",
       "      <td>0.628000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.499000</td>\n",
       "      <td>0.467000</td>\n",
       "      <td>0.445000</td>\n",
       "      <td>0.496000</td>\n",
       "      <td>0.496000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing key: score\n",
      "Pred shape: 1800, Original shape: 1800\n",
      "Processing key: content\n",
      "Pred shape: 1800, Original shape: 1800\n",
      "Processing key: prompt_adherence\n",
      "Pred shape: 1800, Original shape: 1800\n",
      "Processing key: language\n",
      "Pred shape: 1800, Original shape: 1800\n",
      "Processing key: narrativity\n",
      "Pred shape: 1800, Original shape: 1800\n",
      "CURRENT EPOCH: 1.0\n",
      "[DEV] AVG QWK: 0.662\n",
      "[DEV] score QWK: 0.942\n",
      "[DEV] content QWK: 0.819\n",
      "[DEV] organization QWK: 0.673\n",
      "[DEV] word_choice QWK: 0.719\n",
      "[DEV] sentence_fluency QWK: 0.709\n",
      "[DEV] conventions QWK: 0.601\n",
      "[DEV] prompt_adherence QWK: 0.491\n",
      "[DEV] language QWK: 0.499\n",
      "[DEV] narrativity QWK: 0.504\n",
      "------------------------\n",
      "[TEST] AVG QWK: 0.285\n",
      "[TEST] score QWK: 0.269\n",
      "[TEST] content QWK: 0.259\n",
      "[TEST] prompt_adherence QWK: 0.26\n",
      "[TEST] language QWK: 0.331\n",
      "[TEST] narrativity QWK: 0.308\n",
      "------------------------\n",
      "[BEST TEST] AVG QWK: 0.285, epoch: 1.0\n",
      "[BEST TEST] score QWK: 0.269\n",
      "[BEST TEST] content QWK: 0.259\n",
      "[BEST TEST] prompt_adherence QWK: 0.26\n",
      "[BEST TEST] language QWK: 0.331\n",
      "[BEST TEST] narrativity QWK: 0.308\n",
      "--------------------------------------------------------------------------------------------------------------------------\n",
      "Processing key: score\n",
      "Pred shape: 1800, Original shape: 1800\n",
      "Processing key: content\n",
      "Pred shape: 1800, Original shape: 1800\n",
      "Processing key: prompt_adherence\n",
      "Pred shape: 1800, Original shape: 1800\n",
      "Processing key: language\n",
      "Pred shape: 1800, Original shape: 1800\n",
      "Processing key: narrativity\n",
      "Pred shape: 1800, Original shape: 1800\n",
      "CURRENT EPOCH: 2.0\n",
      "[DEV] AVG QWK: 0.674\n",
      "[DEV] score QWK: 0.943\n",
      "[DEV] content QWK: 0.813\n",
      "[DEV] organization QWK: 0.68\n",
      "[DEV] word_choice QWK: 0.745\n",
      "[DEV] sentence_fluency QWK: 0.736\n",
      "[DEV] conventions QWK: 0.642\n",
      "[DEV] prompt_adherence QWK: 0.488\n",
      "[DEV] language QWK: 0.504\n",
      "[DEV] narrativity QWK: 0.512\n",
      "------------------------\n",
      "[TEST] AVG QWK: 0.267\n",
      "[TEST] score QWK: 0.225\n",
      "[TEST] content QWK: 0.254\n",
      "[TEST] prompt_adherence QWK: 0.252\n",
      "[TEST] language QWK: 0.312\n",
      "[TEST] narrativity QWK: 0.289\n",
      "------------------------\n",
      "[BEST TEST] AVG QWK: 0.267, epoch: 2.0\n",
      "[BEST TEST] score QWK: 0.225\n",
      "[BEST TEST] content QWK: 0.254\n",
      "[BEST TEST] prompt_adherence QWK: 0.252\n",
      "[BEST TEST] language QWK: 0.312\n",
      "[BEST TEST] narrativity QWK: 0.289\n",
      "--------------------------------------------------------------------------------------------------------------------------\n",
      "Processing key: score\n",
      "Pred shape: 1800, Original shape: 1800\n",
      "Processing key: content\n",
      "Pred shape: 1800, Original shape: 1800\n",
      "Processing key: prompt_adherence\n",
      "Pred shape: 1800, Original shape: 1800\n",
      "Processing key: language\n",
      "Pred shape: 1800, Original shape: 1800\n",
      "Processing key: narrativity\n",
      "Pred shape: 1800, Original shape: 1800\n",
      "CURRENT EPOCH: 3.0\n",
      "[DEV] AVG QWK: 0.734\n",
      "[DEV] score QWK: 0.954\n",
      "[DEV] content QWK: 0.811\n",
      "[DEV] organization QWK: 0.738\n",
      "[DEV] word_choice QWK: 0.802\n",
      "[DEV] sentence_fluency QWK: 0.752\n",
      "[DEV] conventions QWK: 0.673\n",
      "[DEV] prompt_adherence QWK: 0.622\n",
      "[DEV] language QWK: 0.628\n",
      "[DEV] narrativity QWK: 0.625\n",
      "------------------------\n",
      "[TEST] AVG QWK: 0.481\n",
      "[TEST] score QWK: 0.499\n",
      "[TEST] content QWK: 0.467\n",
      "[TEST] prompt_adherence QWK: 0.445\n",
      "[TEST] language QWK: 0.496\n",
      "[TEST] narrativity QWK: 0.496\n",
      "------------------------\n",
      "[BEST TEST] AVG QWK: 0.481, epoch: 3.0\n",
      "[BEST TEST] score QWK: 0.499\n",
      "[BEST TEST] content QWK: 0.467\n",
      "[BEST TEST] prompt_adherence QWK: 0.445\n",
      "[BEST TEST] language QWK: 0.496\n",
      "[BEST TEST] narrativity QWK: 0.496\n",
      "--------------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def train(\n",
    "    test_prompt_id: int = 1,\n",
    "    experiment_tag: str = \"test\",\n",
    "    seed: int = 11,\n",
    "    num_train_epochs: int = 14,\n",
    "    batch_size: int = 8,\n",
    "    gradient_accumulation: int = 2,\n",
    "    learning_rate: float = 1e-5,\n",
    "    weight_decay: float = 0.01,\n",
    "    chunk_sizes: int = [90, 30, 130, 10]\n",
    "):\n",
    "    seed_all(seed)\n",
    "\n",
    "#     train_dataset = get_subset(\n",
    "#     CustomDataset(f\"/home/tsaibw/Multi_scale/dataset/new_train/encode_prompt_{test_prompt_id}.pkl\"), \n",
    "#     fraction=0.001\n",
    "# )\n",
    "    train_dataset = CustomDataset(f\"/home/tsaibw/Multi_scale/dataset/new_train/encode_prompt_{test_prompt_id}.pkl\")\n",
    "    eval_dataset = CustomDataset(f\"/home/tsaibw/Multi_scale/dataset/new_dev/encode_prompt_{test_prompt_id}.pkl\")\n",
    "    test_dataset = CustomDataset(f\"/home/tsaibw/Multi_scale/dataset/new_test/encode_prompt_{test_prompt_id}.pkl\")\n",
    "    model = Model(\n",
    "        args=args\n",
    "    )\n",
    "    evaluator = Evaluator(eval_dataset, test_dataset, seed)\n",
    "\n",
    "    output_dir = f\"ckpts/Curriculum/Epoch_20/prompt_{test_prompt_id}\"\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        learning_rate = learning_rate,\n",
    "        num_train_epochs = num_train_epochs,\n",
    "        per_device_train_batch_size = batch_size,\n",
    "        per_device_eval_batch_size = batch_size,\n",
    "        gradient_accumulation_steps = gradient_accumulation,\n",
    "        logging_dir = f\"logs/{experiment_tag}/Curriculum/Epoch_20/prompt_{test_prompt_id}\",\n",
    "        evaluation_strategy = \"epoch\",\n",
    "        label_names = [\"scaled_score\"],\n",
    "        save_strategy = \"epoch\",\n",
    "        save_total_limit = 5,\n",
    "        do_eval = True,\n",
    "        load_best_model_at_end = True, \n",
    "        fp16 = False,\n",
    "        remove_unused_columns = True,\n",
    "        metric_for_best_model = \"eval_test_avg\",\n",
    "        greater_is_better = True,\n",
    "        seed = seed,\n",
    "        data_seed = seed,\n",
    "        ddp_find_unused_parameters = False\n",
    "    )\n",
    "            \n",
    "    trainer = BertTrainer(\n",
    "        model = model,\n",
    "        args = training_args,\n",
    "        train_dataset = train_dataset,\n",
    "        eval_dataset = eval_dataset,\n",
    "        test_dataset = test_dataset,\n",
    "        evaluator = evaluator,\n",
    "        callbacks = [EvaluateRecord(output_dir)],\n",
    "        data_collator = default_collate,\n",
    "    )\n",
    "\n",
    "    print('Trainer is using device:', trainer.args.device)\n",
    "    print(test_prompt_id)\n",
    "    trainer.train()\n",
    "    # trainer.train(resume_from_checkpoint = f\"/home/tsaibw/ProTACT_pytorch/ckpts/Curriculum/prompt_{test_prompt_id}/checkpoint-epoch_10\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    for i in range(6,9):\n",
    "        train(test_prompt_id = i)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd54c6b-7fda-4e00-adc9-7b10d4ab9113",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018d8b9e-de68-494c-9b86-ab950ef45b9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env ProTact",
   "language": "python",
   "name": "protact"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
