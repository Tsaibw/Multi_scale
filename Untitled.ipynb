{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f5b1b7a-d68a-46d2-96b5-2847e4eae57a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=2\n"
     ]
    }
   ],
   "source": [
    "!export CUDA_VISIBLE_DEVICES=2\n",
    "%set_env CUDA_VISIBLE_DEVICES=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53396113-8639-48b0-8c51-cae7fe18a6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from transformers import BertModel, BertConfig\n",
    "from torch.optim import Adam\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.nn.utils import clip_grad_value_\n",
    "from tqdm import tqdm\n",
    "from data.dataloader import CustomDataset\n",
    "from model.multi_bert import multiBert\n",
    "from data.scale import get_scaled_down_scores, separate_and_rescale_attributes_for_scoring\n",
    "from utils.evaluate import evaluation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ad4a9ac9-58a3-4ea1-b615-bd592644fb25",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(f'/home/tsaibw/Multi_scale/dataset/new_train/encode_prompt_1.pkl')\n",
    "eval_dataset = CustomDataset(f'/home/tsaibw/Multi_scale/dataset/new_train/encode_prompt_1.pkl')\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=6, shuffle=False, num_workers=4)\n",
    "eval_loader = DataLoader(eval_dataset, batch_size=6, shuffle=False, num_workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bae6c560-21c6-4cc0-a550-d4229b09318c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(len(train_dataset[0]['chunked_documents'][0]))\n",
    "print(len(train_dataset[1]))\n",
    "# print(train_loader[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b2cb6b61-8bcc-4ea3-b204-7824e9b9a1b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_id: torch.Size([6])\n",
      "document_single: torch.Size([6, 3, 3, 512])\n",
      "chunked_documents: <class 'list'>\n",
      "lengths: <class 'list'>\n",
      "hand_craft: torch.Size([6, 52])\n",
      "readability: torch.Size([6, 34])\n",
      "scaled_score: torch.Size([6, 9])\n",
      "torch.Size([6, 17, 3, 90])\n",
      "torch.Size([6, 53, 3, 30])\n",
      "torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "for batch in train_loader:\n",
    "    for key in batch.keys():\n",
    "        value = batch[key]\n",
    "        if isinstance(value, torch.Tensor):\n",
    "            print(f\"{key}: {value.shape}\")  # 打印張量的形狀\n",
    "        else:\n",
    "            print(f\"{key}: {type(value)}\")  # 如果不是張量，打印類型\n",
    "\n",
    "    print(batch['chunked_documents'][0].shape)\n",
    "    print(batch['chunked_documents'][1].shape)\n",
    "    print(batch['lengths'][0].shape)\n",
    "    break  # 測試一個批次即可prompt_id: torch.Size([10]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9686b02b-b0be-4177-bb4e-3cfda2050f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "torch.manual_seed(11)\n",
    "\n",
    "class NerConfig:\n",
    "    def __init__(self):\n",
    "        self.lr = 1e-3\n",
    "        self.epoch = 10\n",
    "        self.batch_size = 1\n",
    "        self.device = \"cuda\"\n",
    "        # self.chunk_sizes = [90]\n",
    "        self.chunk_sizes = [90, 30, 130, 10]\n",
    "        self.data_file = \"/home/tsaibw/Multi_scale/ckps/only_score\"\n",
    "args = NerConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4bf3ebee-fdf0-4123-8b94-133c80fccdf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:   0% 0/8953 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "forward() missing 2 required positional arguments: 'readability' and 'hand_craft'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 37\u001b[0m\n\u001b[1;32m     34\u001b[0m document_single \u001b[38;5;241m=\u001b[39m document_single\u001b[38;5;241m.\u001b[39mto(args\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m     35\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 37\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mmulti_bert_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdocument_single\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdocument_single\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked_documents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked_documents\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlengths\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlengths\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     42\u001b[0m \n\u001b[1;32m     43\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m loss, inverse_predictions, inverse_labels \u001b[38;5;241m=\u001b[39m multi_bert_model\u001b[38;5;241m.\u001b[39mcompute_loss(predictions, label, id_, args\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m     46\u001b[0m total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m/opt/miniconda/envs/protact/lib/python3.8/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "\u001b[0;31mTypeError\u001b[0m: forward() missing 2 required positional arguments: 'readability' and 'hand_craft'"
     ]
    }
   ],
   "source": [
    "# train normalize\n",
    "\n",
    "def save_checkpoint(state, filename=\"checkpoint.pth.tar\"):\n",
    "    torch.save(state, filename)\n",
    "\n",
    "\n",
    "def print_gradients(model):\n",
    "    for name, parameter in model.named_parameters():\n",
    "        if parameter.grad is not None:\n",
    "            print(f\"{name} - Gradient Norm: {parameter.grad.norm().item()}\")\n",
    "        else:\n",
    "            print(f\"{name} - No gradient\")\n",
    "\n",
    "\n",
    "for i in range(1,9):\n",
    "    multi_bert_model = multiBert(args.chunk_sizes)  \n",
    "    multi_bert_model.to(args.device)  \n",
    "    optimizer = Adam(multi_bert_model.parameters(), lr = args.lr) \n",
    "    \n",
    "    train_dataset = CustomDataset(f'/home/tsaibw/data/nas07/PersonalData/tsaibw/ASAP/dataset/train/encode_prompt_{i}.pkl')\n",
    "    eval_dataset = CustomDataset(f'/home/tsaibw/data/nas07/PersonalData/tsaibw/ASAP/dataset/test/encode_prompt_{i}.pkl')\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=args.batch_size, shuffle=False, num_workers=4)\n",
    "    eval_loader = DataLoader(eval_dataset, batch_size=args.batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "    train_loss_list , eval_loss_list = [] ,[] \n",
    "    os.makedirs(f\"{args.data_file}/prompt{i}\", exist_ok=True)\n",
    "    \n",
    "    for epoch in range(args.epoch):\n",
    "        multi_bert_model.train()\n",
    "        total_loss = 0\n",
    "\n",
    "        for document_single, chunked_documents, label, id_, lengths in tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{args.epoch}\"):\n",
    "            document_single = document_single.to(args.device)\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            predictions = multi_bert_model(\n",
    "                    document_single=document_single,\n",
    "                    chunked_documents=chunked_documents,\n",
    "                    device=args.device,\n",
    "                    lengths=lengths,\n",
    "\n",
    "            )\n",
    "            \n",
    "            loss, inverse_predictions, inverse_labels = multi_bert_model.compute_loss(predictions, label, id_, args.device)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        eval_loss, qwk_score, pearson_score = multi_bert_model.evaluate(eval_loader, device = args.device)\n",
    "        \n",
    "        print(f\"Epoch {epoch}, Train Loss: {total_loss / len(train_loader)}\")\n",
    "        print(f\"Test Loss: {eval_loss}\")\n",
    "        train_loss_list.append(total_loss / len(train_loader))\n",
    "        eval_loss_list.append(eval_loss)\n",
    "\n",
    "        qwk_path = f\"{args.data_file}/prompt{i}/result.txt\"\n",
    "        with open(qwk_path, \"a\") as f:\n",
    "            f.write(f\"Epoch {epoch + 1}/{args.epoch}, QWK: {qwk_score}, Pearson: {pearson_score}, train_loss: {train_loss_list[-1]}, eval_loss: {eval_loss_list[-1]}\\n\")\n",
    "  \n",
    "        checkpoint_path = f\"{args.data_file}/prompt{i}/epoch_{epoch+1}_checkpoint.pth.tar\"\n",
    "        save_checkpoint({\n",
    "          'epoch': epoch + 1,\n",
    "          'state_dict': multi_bert_model.state_dict(),\n",
    "          'optimizer': optimizer.state_dict(),\n",
    "          'train_loss': total_loss / len(train_loader),\n",
    "          'eval_loss': eval_loss\n",
    "        }, filename = checkpoint_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "04782ad6-7f0a-4a55-a61c-6fdc872f1930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 3, 1, 10]\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset[3][4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "84c2f8bb-290c-4e9c-a3e0-1ede7fee26ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n",
      "53\n",
      "12\n",
      "184\n"
     ]
    }
   ],
   "source": [
    "a = train_dataset[3][1]\n",
    "for i in range(4):\n",
    "    print(len(a[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fb63ac33-078e-40c2-940e-55c56d91fdbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([53, 3, 30])\n",
      "tensor([[[ 101, 1000, 2108,  ..., 2487, 1012,  102],\n",
      "         [   0,    0,    0,  ...,    0,    0,    0],\n",
      "         [   1,    1,    1,  ...,    1,    1,    1]],\n",
      "\n",
      "        [[ 101, 2033, 1998,  ..., 2165, 1037,  102],\n",
      "         [   0,    0,    0,  ...,    0,    0,    0],\n",
      "         [   1,    1,    1,  ...,    1,    1,    1]],\n",
      "\n",
      "        [[ 101, 2096, 2077,  ...,    0,    0,    0],\n",
      "         [   0,    0,    0,  ...,    0,    0,    0],\n",
      "         [   1,    1,    1,  ...,    0,    0,    0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 101,  102,    0,  ...,    0,    0,    0],\n",
      "         [   0,    0,    0,  ...,    0,    0,    0],\n",
      "         [   1,    1,    0,  ...,    0,    0,    0]],\n",
      "\n",
      "        [[ 101,  102,    0,  ...,    0,    0,    0],\n",
      "         [   0,    0,    0,  ...,    0,    0,    0],\n",
      "         [   1,    1,    0,  ...,    0,    0,    0]],\n",
      "\n",
      "        [[ 101,  102,    0,  ...,    0,    0,    0],\n",
      "         [   0,    0,    0,  ...,    0,    0,    0],\n",
      "         [   1,    1,    0,  ...,    0,    0,    0]]])\n",
      "tensor([[  101,  1000,  2108, 11752,  2003,  2524,  2000,  2079,  1010,  1030,\n",
      "          9700,  2487,  1045,  2079,  3342,  1037,  2051,  2043,  1045,  2001,\n",
      "          5776,  1012,  2023,  2001,  2012,  1030,  2103,  2487,  1012,   102],\n",
      "        [  101,  2033,  1998,  2026,  2177,  2018,  2000,  3524,  2005,  3071,\n",
      "          2000,  2131,  2067,  2000,  1996,  3902,  1012,  2057,  2020,  1996,\n",
      "          2034,  3924,  2000,  1996,  3902,  2061,  2009,  2165,  1037,   102],\n",
      "        [  101,  2096,  2077,  2027,  2234,  1012,  1030,  9700,  2487,  2077,\n",
      "          2027,  2106,  1045,  2001,  2004,  5475,  1998,  5776,  2004,  2064,\n",
      "          2022,  1012,  1000,   102,     0,     0,     0,     0,     0,     0]])\n",
      "torch.Size([3, 30])\n"
     ]
    }
   ],
   "source": [
    "print(a[1].shape)\n",
    "print(a[1])\n",
    "print(a[1][:3,0])\n",
    "print(a[1][:3,0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9fb42856-9fa1-4656-adcb-ecb7b9ea22b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# 模擬輸入特徵 (batch_size=2, seq_len=3, hidden_dim=4)\n",
    "h = torch.tensor([\n",
    "    [[1.0, 2.0, 3.0, 4.0],  # 第一個樣本的第1時間步\n",
    "     [5.0, 6.0, 7.0, 8.0],  # 第一個樣本的第2時間步\n",
    "     [9.0, 10.0, 11.0, 12.0]],  # 第一個樣本的第3時間步\n",
    "\n",
    "    [[2.0, 3.0, 4.0, 5.0],  # 第二個樣本的第1時間步\n",
    "     [6.0, 7.0, 8.0, 9.0],  # 第二個樣本的第2時間步\n",
    "     [10.0, 11.0, 12.0, 13.0]]  # 第二個樣本的第3時間步\n",
    "])  # shape: [2, 3, 4]\n",
    "\n",
    "# 模擬注意力權重 (batch_size=2, seq_len=3, 1)\n",
    "weight = torch.tensor([\n",
    "    [[0.1],  # 第一個樣本的第1時間步的權重\n",
    "     [0.5],  # 第一個樣本的第2時間步的權重\n",
    "     [0.4]],  # 第一個樣本的第3時間步的權重\n",
    "\n",
    "    [[0.2],  # 第二個樣本的第1時間步的權重\n",
    "     [0.3],  # 第二個樣本的第2時間步的權重\n",
    "     [0.5]]  # 第二個樣本的第3時間步的權重\n",
    "])  # shape: [2, 3, 1]\n",
    "expanded_weight = weight.repeat(1, 2, h.size(2))  # 在最後一個維度重複 hidden_dim 次\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a3c810bf-f25d-4338-aac7-ea75e58e47d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 4])\n",
      "torch.Size([3, 4])\n"
     ]
    }
   ],
   "source": [
    "print(h.shape)\n",
    "print(h[0].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5c9e3a55-9823-4231-8ad0-73884975404c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 1])\n",
      "torch.Size([2, 6, 4])\n",
      "tensor([[[0.1000, 0.1000, 0.1000, 0.1000],\n",
      "         [0.5000, 0.5000, 0.5000, 0.5000],\n",
      "         [0.4000, 0.4000, 0.4000, 0.4000],\n",
      "         [0.1000, 0.1000, 0.1000, 0.1000],\n",
      "         [0.5000, 0.5000, 0.5000, 0.5000],\n",
      "         [0.4000, 0.4000, 0.4000, 0.4000]],\n",
      "\n",
      "        [[0.2000, 0.2000, 0.2000, 0.2000],\n",
      "         [0.3000, 0.3000, 0.3000, 0.3000],\n",
      "         [0.5000, 0.5000, 0.5000, 0.5000],\n",
      "         [0.2000, 0.2000, 0.2000, 0.2000],\n",
      "         [0.3000, 0.3000, 0.3000, 0.3000],\n",
      "         [0.5000, 0.5000, 0.5000, 0.5000]]])\n",
      "torch.Size([2, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "print(weight.shape)\n",
    "print(expanded_weight.shape)\n",
    "print(expanded_weight)\n",
    "print(h.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d6e9e901-99dd-43bd-9298-4a2042fae4d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 4])\n",
      "tensor([[[0.1000, 0.2000, 0.3000, 0.4000],\n",
      "         [2.5000, 3.0000, 3.5000, 4.0000],\n",
      "         [3.6000, 4.0000, 4.4000, 4.8000]],\n",
      "\n",
      "        [[0.4000, 0.6000, 0.8000, 1.0000],\n",
      "         [1.8000, 2.1000, 2.4000, 2.7000],\n",
      "         [5.0000, 5.5000, 6.0000, 6.5000]]])\n"
     ]
    }
   ],
   "source": [
    "out = torch.mul(h, expanded_weight)\n",
    "print(out.shape)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0b22ff4e-56c6-4ed8-b9ab-f19851b80440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.1000, 0.2000, 0.3000, 0.4000],\n",
      "         [2.5000, 3.0000, 3.5000, 4.0000],\n",
      "         [3.6000, 4.0000, 4.4000, 4.8000]],\n",
      "\n",
      "        [[0.4000, 0.6000, 0.8000, 1.0000],\n",
      "         [1.8000, 2.1000, 2.4000, 2.7000],\n",
      "         [5.0000, 5.5000, 6.0000, 6.5000]]])\n"
     ]
    }
   ],
   "source": [
    "out = h * weight\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5367261d-c479-4876-a61b-2ffe9584b891",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env ProTact",
   "language": "python",
   "name": "protact"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
